{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import getpass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import getpass\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Uma LLM, ou Mestrado em Direito (Master of Laws), é um programa de pós-graduação que oferece uma formação mais especializada e avançada na área jurídica para profissionais que já possuem um diploma de graduação em Direito.\\n\\nServe para aprofundar o conhecimento jurídico em uma área específica do Direito, como direito tributário, direito internacional, direito ambiental, entre outros. Além disso, a LLM pode abrir portas para novas oportunidades de carreira, como cargos de liderança, consultoria jurídica, docência em instituições de ensino superior, entre outros. Também pode ser útil para quem deseja se especializar em uma área específica do Direito ou se preparar para o exercício da advocacia em países estrangeiros.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 188, 'prompt_tokens': 14, 'total_tokens': 202, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CMkooEzea4DQbW1tAXtczFN9KWbku', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5cfa9c10-59a4-43bf-a990-434083ec31bb-0', usage_metadata={'input_tokens': 14, 'output_tokens': 188, 'total_tokens': 202, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = chat.invoke(\"pra que serve uma llm?\")\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Using a Large Language Model (LLM) like GPT-3 or GPT-4 involves several basic steps, depending on the context and purpose. Here are some common ways to interact with an LLM:\\n\\n1. **Text Generation**: You can provide a prompt or input text, and the model will generate coherent and contextually relevant text in response. This can be used for creative writing, brainstorming, or content creation.\\n\\n   Example: \"Write a short story about a dragon and a knight.\"\\n\\n2. **Question Answering**: You can ask the model questions, and it will provide answers based on the information it has been trained on.\\n\\n   Example: \"What are the main causes of climate change?\"\\n\\n3. **Language Translation**: LLMs can help with translating text from one language to another.\\n\\n   Example: \"Translate \\'Hello, how are you?\\' into Spanish.\"\\n\\n4. **Summarization**: You can input long documents or articles, and the model can produce concise summaries.\\n\\n   Example: \"Summarize the main points of this article.\"\\n\\n5. **Conversational Agents**: LLMs can power chatbots or virtual assistants, enabling them to engage in dialogue with users.\\n\\n   Example: \"What can you tell me about the weather today?\"\\n\\n6. **Code Generation and Debugging**: Developers can use LLMs to generate code snippets, offer explanations of code, or assist in debugging.\\n\\n   Example: \"Write a Python function to calculate the Fibonacci sequence.\"\\n\\n7. **Content Improvement**: You can ask the model to help improve an existing piece of text, making it clearer, more engaging, or grammatically correct.\\n\\n   Example: \"Can you help me rewrite this paragraph to make it more persuasive?\"\\n\\n8. **Customization and Fine-Tuning**: For specific use cases, LLMs can be fine-tuned on particular datasets to improve relevance and accuracy in particular domains, like legal texts, medical information, or technical jargon.\\n\\nTo effectively use an LLM, it\\'s important to formulate clear and specific prompts. The quality of the interaction often depends on how well the input is phrased, so experimentation with different phrasing can lead to better results. Always keep in mind the limitations of LLMs, such as potential inaccuracies or biases in generated content.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 465, 'prompt_tokens': 16, 'total_tokens': 481, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CMkZxbMTB8Ns9jzqADKgZfV5pqILm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--822e3452-3e03-4fa8-aaf1-073057848d14-0', usage_metadata={'input_tokens': 16, 'output_tokens': 465, 'total_tokens': 481, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(\"What is the basic usage for llm?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Using a Large Language Model (LLM) like GPT-3 or GPT-4 involves several basic steps, depending on the context and purpose. Here are some common ways to interact with an LLM:\\n\\n1. **Text Generation**: You can provide a prompt or input text, and the model will generate coherent and contextually relevant text in response. This can be used for creative writing, brainstorming, or content creation.\\n\\n   Example: \"Write a short story about a dragon and a knight.\"\\n\\n2. **Question Answering**: You can ask the model questions, and it will provide answers based on the information it has been trained on.\\n\\n   Example: \"What are the main causes of climate change?\"\\n\\n3. **Language Translation**: LLMs can help with translating text from one language to another.\\n\\n   Example: \"Translate \\'Hello, how are you?\\' into Spanish.\"\\n\\n4. **Summarization**: You can input long documents or articles, and the model can produce concise summaries.\\n\\n   Example: \"Summarize the main points of this article.\"\\n\\n5. **Conversational Agents**: LLMs can power chatbots or virtual assistants, enabling them to engage in dialogue with users.\\n\\n   Example: \"What can you tell me about the weather today?\"\\n\\n6. **Code Generation and Debugging**: Developers can use LLMs to generate code snippets, offer explanations of code, or assist in debugging.\\n\\n   Example: \"Write a Python function to calculate the Fibonacci sequence.\"\\n\\n7. **Content Improvement**: You can ask the model to help improve an existing piece of text, making it clearer, more engaging, or grammatically correct.\\n\\n   Example: \"Can you help me rewrite this paragraph to make it more persuasive?\"\\n\\n8. **Customization and Fine-Tuning**: For specific use cases, LLMs can be fine-tuned on particular datasets to improve relevance and accuracy in particular domains, like legal texts, medical information, or technical jargon.\\n\\nTo effectively use an LLM, it\\'s important to formulate clear and specific prompts. The quality of the interaction often depends on how well the input is phrased, so experimentation with different phrasing can lead to better results. Always keep in mind the limitations of LLMs, such as potential inaccuracies or biases in generated content.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 465,\n",
       "   'prompt_tokens': 16,\n",
       "   'total_tokens': 481,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_51db84afab',\n",
       "  'id': 'chatcmpl-CMkZxbMTB8Ns9jzqADKgZfV5pqILm',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run--822e3452-3e03-4fa8-aaf1-073057848d14-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 16,\n",
       "  'output_tokens': 465,\n",
       "  'total_tokens': 481,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# # Index chunks\n",
    "# _ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "def extract_data():\n",
    "    text_chunks = []\n",
    "    files = filter(lambda f: f.lower().endswith(\".pdf\"), os.listdir(\"./content_source/pdf\"))\n",
    "    file_list = list(files)\n",
    "    for file in file_list:\n",
    "        loader = PyPDFLoader(os.path.join('content_source', 'pdf', file))\n",
    "        text_chunks += loader.load_and_split(text_splitter=RecursiveCharacterTextSplitter(\n",
    "            chunk_size = 512,\n",
    "            chunk_overlap = 30,\n",
    "            length_function = len,\n",
    "            separators= [\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "        ))\n",
    "    vectorstore = FAISS.from_documents(documents=text_chunks, embedding=OpenAIEmbeddings(api_key=OPENAI_API_KEY))\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "vector_store = extract_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content discusses advancements in machine learning and deep learning applications within the context of Directed Energy Deposition (DED) additive manufacturing. It focuses on using image analysis of melt pools to predict the quality of printed components, specifically by estimating deviations in printing focus. The work aims to enhance prediction accuracy by incorporating temporal information from preceding images.\n"
     ]
    }
   ],
   "source": [
    "# response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "response = graph.invoke({\"question\": \"What is this content all about?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is this content all about?',\n",
       " 'context': [Document(id='d92c7eed-4701-44f8-b069-301d436a9359', metadata={'producer': 'Adobe PSL 1.2e for Canon\\x00', 'creator': 'Canon iR-ADV C5250  PDF', 'creationdate': '2025-08-04T12:26:55+03:00', 'source': 'content_source/pdf/projeto_leonel-rev_kan1.pdf', 'total_pages': 39, 'page': 29, 'page_label': '30'}, page_content='58'),\n",
       "  Document(id='f17b0ab1-2940-4380-94b7-31273af7e9ba', metadata={'producer': 'Adobe PSL 1.2e for Canon\\x00', 'creator': 'Canon iR-ADV C5250  PDF', 'creationdate': '2025-08-04T12:26:55+03:00', 'source': 'content_source/pdf/projeto_leonel-rev_kan1.pdf', 'total_pages': 39, 'page': 38, 'page_label': '39'}, page_content='Elgendy, Mohamed. Deep learningfor vision systems. Simon and Schuster, 2020.\\nEra, Israt Zarin, et a1.,2023. \"Machine learning in Directed Energy Deposition (DED) additive manufacturing: A state-\\noÊthe-art review.\" Manufacturing Letters 35, pp. 689-700.\\nJogin, Manjunath,etal.,20l8. \"Feature extraction using convolution neural networks (Cl.lN) and deep learning.\" 2018\\n3rd IEEE international conference on recenl trends in electronics, information & communication technologt\\n(RTETCT). rEEE,2018.'),\n",
       "  Document(id='7d22fcda-8f73-4bcf-b715-e8b9a996de91', metadata={'producer': 'Adobe PSL 1.2e for Canon\\x00', 'creator': 'Canon iR-ADV C5250  PDF', 'creationdate': '2025-08-04T12:26:55+03:00', 'source': 'content_source/pdf/projeto_leonel-rev_kan1.pdf', 'total_pages': 39, 'page': 35, 'page_label': '36'}, page_content='monitoring. The review of the applications within each one of these 3 groups, leads to the conclusion that the melt pool\\nfeatures play a crucial role on the effort ofpredicting characteristics ofthe printed component.\\nThis work is intended to use images of melt pools during deposition to estimate deviations from printing focus, which\\nís recognized as a critical parameter to layer surface quality control Fig. I, from Ribeiro et al. (2023), was taken as main'),\n",
       "  Document(id='6b68de15-4916-4e43-8638-746a0a485e69', metadata={'producer': 'Adobe PSL 1.2e for Canon\\x00', 'creator': 'Canon iR-ADV C5250  PDF', 'creationdate': '2025-08-04T12:26:55+03:00', 'source': 'content_source/pdf/projeto_leonel-rev_kan1.pdf', 'total_pages': 39, 'page': 36, 'page_label': '37'}, page_content='3.3 Temporalinformation\\nThe base article performs regression on each image independently and achieves good results with a mean absolute\\nerror close to 0.25 mm. The current work aims to improve this metric by investigating the impact of adding information\\nabout the region right before the molten pool to be predicted. As the deposition is a continous process, the image n is\\ncloselly correlated with image n- I .')],\n",
       " 'answer': 'The content discusses advancements in machine learning and deep learning applications within the context of Directed Energy Deposition (DED) additive manufacturing. It focuses on using image analysis of melt pools to predict the quality of printed components, specifically by estimating deviations in printing focus. The work aims to enhance prediction accuracy by incorporating temporal information from preceding images.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
